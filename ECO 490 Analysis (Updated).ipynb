{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "# Define the API URL \n",
    "url = \"https://api.census.gov/data/2019/acs/acs1/pums?get=RACBLK,RACAIAN,RACWHT,MAR,SEX,ENG,HISP,SCHL,MIGSP,YOEP&AGEP=18:99&WAGP=0&WAGP=4:999999&NATIVITY=2&AGEP=18:99&WAGP=0&WAGP=4:999999\"\n",
    "\n",
    "# Make the API request with SSL verification disabled\n",
    "response = requests.get(url, verify=False)\n",
    "\n",
    "# checks if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data (357817, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACBLK</th>\n",
       "      <th>RACAIAN</th>\n",
       "      <th>RACWHT</th>\n",
       "      <th>MAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ENG</th>\n",
       "      <th>HISP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MIGSP</th>\n",
       "      <th>YOEP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WAGP</th>\n",
       "      <th>NATIVITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>21</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1989</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1968</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>2015</td>\n",
       "      <td>18</td>\n",
       "      <td>1200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>53</td>\n",
       "      <td>31200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RACBLK RACAIAN RACWHT MAR SEX ENG HISP SCHL MIGSP  YOEP AGEP   WAGP NATIVITY\n",
       "0      0       0      0   5   2   0    1   19     0  1998   21   2000        2\n",
       "1      0       0      0   1   1   4    1   16     0  1989   71      0        2\n",
       "2      0       0      0   1   1   3    1    8     0  1968   83      0        2\n",
       "3      0       0      1   5   1   0    2   16    48  2015   18   1200        2\n",
       "4      0       0      1   5   1   4    2   16     0  2007   53  31200        2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import statsmodels.api as sm \n",
    "df = df.dropna() # drop missing values in data set\n",
    "print('shape of data', df.shape) # print shape of data\n",
    "df.head()  # print first five rows of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data for analysis \n",
    "\n",
    "df.dropna(inplace=True) # drop missing values in data set\n",
    "\n",
    "df['WAGP'] = pd.to_numeric(df['WAGP'], errors='coerce') \n",
    "    # convert wage to numeric\n",
    "df['LOG_WAGE'] = np.log(df['WAGP']) # create a new variable that is the log of wage\n",
    "\n",
    "#English Fluency Values --> zero value was eliminated to only look at individuals with a second language \n",
    "    # 1 and 2 will be if the individual has a strong English fluency and 3 and 4 being weak level 0f English fluency\n",
    "df['ENG'] = pd.to_numeric(df['ENG'], errors='coerce') \n",
    "    # convert English fluency to numeric\n",
    "df = df[df['ENG'] != '0'] \n",
    "    # drop missing values in data set\n",
    "df['ENGLISH'] = df['ENG'].map(lambda x: 1 if x < 3 else 0)\n",
    "    # changes it into a binary, 1 being strong English fluency and 0 being weak English fluency\n",
    "\n",
    "# Education Attainment\n",
    "    # 01-15 -Did not complete high school. \n",
    "    # 16-High school graduate - regular high school diploma; \n",
    "    # 17-High school graduate - GED or alternative credential\n",
    "    # 18-19-Some college, no degree, \n",
    "    # 20-Associate's degree; \n",
    "    # 21-Bachelor's degree; \n",
    "    # 22-24-Post graduate degree;\n",
    "df['SCHL'] = pd.to_numeric(df['SCHL'], errors='coerce')\n",
    "    # convert education to numeric\n",
    "df = df[df['SCHL'] != '0']\n",
    "    # drop missing values in data set\n",
    "df['NOHS'] = df['SCHL'].map(lambda x: 1 if x < 16 else 0) \n",
    "    # changes it into a binary, 1 being no high school and 0 being high school or higher\n",
    "df['HS'] = df['SCHL'].map(lambda x: 1 if x == 16 or x == 17 else 0)\n",
    "    # changes it into a binary, 1 being high school or GED and 0 being no high school or higher\n",
    "df['COLL'] = df['SCHL'].map(lambda x: 1 if x == 18 or x == 19 or x == 20 else 0)\n",
    "    # changes it into a binary, 1 being some college or associates and 0 being no college or higher\n",
    "df['BACH'] = df['SCHL'].map(lambda x: 1 if x == 21 else 0)\n",
    "    # changes it into a binary, 1 being a bachelors degree and 0 being no bachelors or higher\n",
    "df['POST'] = df['SCHL'].map(lambda x: 1 if x > 21 else 0)\n",
    "    # changes it into a binary, 1 being a post graduate degree and 0 being no post graduate or higher\n",
    "# age \n",
    "df['AGEP']= pd.to_numeric(df['AGEP'], errors='coerce')\n",
    "    # convert age to numeric\n",
    "# Gender \n",
    "df['SEX'] = pd.to_numeric(df['SEX'], errors='coerce')\n",
    "    # convert sex to numeric \n",
    "df['Male'] = df['SEX'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being male\n",
    "\n",
    "#Martial Status\n",
    "    # 1-Married\n",
    "    # 2-Divorced\n",
    "    # 3-Separated\n",
    "    # 4-Widowed\n",
    "    # 5-Never married\n",
    "df['MAR'] = pd.to_numeric(df['MAR'], errors='coerce')   \n",
    "    # convert marital status to numeric \n",
    "df['MARRIED'] = df['MAR'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being married and 0 being not married\n",
    "\n",
    "#Continental Origin, In the hopes of making the data more manageable, I will only group people by continent of origin not country. \n",
    "df['MIGSP'] = pd.to_numeric(df['MIGSP'], errors='coerce')\n",
    "    # convert continental origin to numeric \n",
    "df['EURO'] = df['MIGSP'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being European and 0 being non-European\n",
    "df['AFRICA'] = df['MIGSP'].map(lambda x: 1 if x == 2 else 0)\n",
    "    # changes it into a binary, 1 being African and 0 being non-African\n",
    "df['NORTH'] = df['MIGSP'].map(lambda x: 1 if x == 3 else 0)\n",
    "    # changes it into a binary, 1 being North American and 0 being non-North American\n",
    "df['South'] = df['MIGSP'].map(lambda x: 1 if x == 4 else 0)\n",
    "    # changes it into a binary, 1 being South/Central American and 0 being non-South American\n",
    "df['ASIA'] = df['MIGSP'].map(lambda x: 1 if x == 5 else 0)\n",
    "    # changes it into a binary, 1 being Asian and 0 being non-Asian\n",
    "df['OCEANIA'] = df['MIGSP'].map(lambda x: 1 if x == 6 else 0)\n",
    "    # changes it into a binary, 1 being Oceanian and 0 being non-Oceanian\n",
    "\n",
    "#Hispanic Origin\n",
    "df['HISP'] = pd.to_numeric(df['HISP'], errors='coerce')\n",
    "df['HISPANIC'] = df['HISP'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being Hispanic and 0 being non-Hispanic\n",
    "\n",
    "#Race\n",
    "df['RACWHT'] = pd.to_numeric(df['RACWHT'], errors='coerce')\n",
    "df['RACBLK'] = pd.to_numeric(df['RACBLK'], errors='coerce')\n",
    "df['WHITE'] = df['RACWHT'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being White and 0 being non-White\n",
    "df['BLACK'] = df['RACBLK'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being Black and 0 being non-Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary \n",
    "df.dropna(inplace=True) # drop missing values in data set\n",
    "selected_columns = ['LOG_WAGE', 'ENGLISH', 'NOHS', 'HS', 'COLL', 'BACH', 'POST', 'AGEP', 'Male', 'MARRIED', 'EURO', 'AFRICA', 'NORTH', 'South', 'ASIA', 'OCEANIA', 'HISPANIC', 'WHITE', 'BLACK']\n",
    "summary = df[selected_columns].describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs and Infs\n",
    "print(df.isnull().sum())  # Count NaNs in each column\n",
    "print(np.isinf(df).sum())  # Count Infs in each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaNs\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Impute NaNs with a specific value\n",
    "#df.fillna(value, inplace=True)\n",
    "\n",
    "# Replace Infs with a specific value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with Infs\n",
    "df = df[~df.isin([np.inf, -np.inf]).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression model\n",
    "Predictor_columns = ['LOG_WAGE', 'NOHS', 'HS', 'COLL', 'BACH', 'POST', 'AGEP', 'Male', 'MARRIED', 'EURO', 'AFRICA', 'NORTH', 'South', 'ASIA', 'OCEANIA', 'HISPANIC', 'WHITE', 'BLACK']\n",
    "probit_model = sm.Probit(df['ENGLISH'], df[Predictor_columns]) \n",
    "probit_result = probit_model.fit() # fit probit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solving for multicolinarity\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Initialize Ridge regression model with regularization parameter alpha\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "\n",
    "# Fit Ridge regression model\n",
    "ridge_model.fit(X_train, y_train) # Need to define these variables. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DATA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
