{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.census.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       RACBLK RACAIAN RACWHT MAR SEX ENG HISP SCHL MIGSP  YOEP AGEP    WAGP  \\\n",
      "0           0       0      0   5   2   0    1   19     0  1998   21    2000   \n",
      "1           0       0      0   1   1   4    1   16     0  1989   71       0   \n",
      "2           0       0      0   1   1   3    1    8     0  1968   83       0   \n",
      "3           0       0      1   5   1   0    2   16    48  2015   18    1200   \n",
      "4           0       0      1   5   1   4    2   16     0  2007   53   31200   \n",
      "...       ...     ...    ...  ..  ..  ..  ...  ...   ...   ...  ...     ...   \n",
      "357812      0       0      1   2   1   1    2   17     0  1962   86   50000   \n",
      "357813      0       0      1   3   2   1    2   15     0  1974   62    4500   \n",
      "357814      0       0      1   3   2   1    1   21     0  1998   60       0   \n",
      "357815      0       0      1   1   1   1    1   22     0  1973   77  120000   \n",
      "357816      0       0      1   5   2   0    3   21     0  2000   47       0   \n",
      "\n",
      "       NATIVITY  \n",
      "0             2  \n",
      "1             2  \n",
      "2             2  \n",
      "3             2  \n",
      "4             2  \n",
      "...         ...  \n",
      "357812        2  \n",
      "357813        2  \n",
      "357814        2  \n",
      "357815        2  \n",
      "357816        2  \n",
      "\n",
      "[357817 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "# Define the API URL \n",
    "url = \"https://api.census.gov/data/2019/acs/acs1/pums?get=RACBLK,RACAIAN,RACWHT,MAR,SEX,ENG,HISP,SCHL,MIGSP,YOEP&AGEP=18:99&WAGP=0&WAGP=4:999999&NATIVITY=2&AGEP=18:99&WAGP=0&WAGP=4:999999\"\n",
    "\n",
    "# Make the API request with SSL verification disabled\n",
    "response = requests.get(url, verify=False)\n",
    "\n",
    "# checks if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data (357817, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACBLK</th>\n",
       "      <th>RACAIAN</th>\n",
       "      <th>RACWHT</th>\n",
       "      <th>MAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ENG</th>\n",
       "      <th>HISP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MIGSP</th>\n",
       "      <th>YOEP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WAGP</th>\n",
       "      <th>NATIVITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>21</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1989</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1968</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>2015</td>\n",
       "      <td>18</td>\n",
       "      <td>1200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>53</td>\n",
       "      <td>31200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RACBLK RACAIAN RACWHT MAR SEX ENG HISP SCHL MIGSP  YOEP AGEP   WAGP NATIVITY\n",
       "0      0       0      0   5   2   0    1   19     0  1998   21   2000        2\n",
       "1      0       0      0   1   1   4    1   16     0  1989   71      0        2\n",
       "2      0       0      0   1   1   3    1    8     0  1968   83      0        2\n",
       "3      0       0      1   5   1   0    2   16    48  2015   18   1200        2\n",
       "4      0       0      1   5   1   4    2   16     0  2007   53  31200        2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import statsmodels.api as sm \n",
    "df = df.dropna() # drop missing values in data set\n",
    "print('shape of data', df.shape) # print shape of data\n",
    "df.head()  # print first five rows of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Transforming the data for analysis \n",
    "\n",
    "df.dropna(inplace=True) # drop missing values in data set\n",
    "\n",
    "df['WAGP'] = pd.to_numeric(df['WAGP'], errors='coerce') \n",
    "    # convert wage to numeric\n",
    "df['LOG_WAGE'] = np.log(df['WAGP']) # create a new variable that is the log of wage\n",
    "\n",
    "#English Fluency Values --> zero value was eliminated to only look at individuals with a second language \n",
    "    # 1 and 2 will be if the individual has a strong English fluency and 3 and 4 being weak level 0f English fluency\n",
    "df['ENG'] = pd.to_numeric(df['ENG'], errors='coerce') \n",
    "    # convert English fluency to numeric\n",
    "df = df[df['ENG'] != '0'] \n",
    "    # drop missing values in data set\n",
    "df['ENGLISH'] = df['ENG'].map(lambda x: 1 if x < 3 else 0)\n",
    "    # changes it into a binary, 1 being strong English fluency and 0 being weak English fluency\n",
    "\n",
    "# Education Attainment\n",
    "    # 01-15 -Did not complete high school. \n",
    "    # 16-High school graduate - regular high school diploma; \n",
    "    # 17-High school graduate - GED or alternative credential\n",
    "    # 18-19-Some college, no degree, \n",
    "    # 20-Associate's degree; \n",
    "    # 21-Bachelor's degree; \n",
    "    # 22-24-Post graduate degree;\n",
    "df['SCHL'] = pd.to_numeric(df['SCHL'], errors='coerce')\n",
    "    # convert education to numeric\n",
    "df = df[df['SCHL'] != '0']\n",
    "    # drop missing values in data set\n",
    "df['NOHS'] = df['SCHL'].map(lambda x: 1 if x < 16 else 0) \n",
    "    # changes it into a binary, 1 being no high school and 0 being high school or higher\n",
    "df['HS'] = df['SCHL'].map(lambda x: 1 if x == 16 or x == 17 else 0)\n",
    "    # changes it into a binary, 1 being high school or GED and 0 being no high school or higher\n",
    "df['COLL'] = df['SCHL'].map(lambda x: 1 if x == 18 or x == 19 or x == 20 else 0)\n",
    "    # changes it into a binary, 1 being some college or associates and 0 being no college or higher\n",
    "df['BACH'] = df['SCHL'].map(lambda x: 1 if x == 21 else 0)\n",
    "    # changes it into a binary, 1 being a bachelors degree and 0 being no bachelors or higher\n",
    "df['POST'] = df['SCHL'].map(lambda x: 1 if x > 21 else 0)\n",
    "    # changes it into a binary, 1 being a post graduate degree and 0 being no post graduate or higher\n",
    "# age \n",
    "df['AGEP']= pd.to_numeric(df['AGEP'], errors='coerce')\n",
    "    # convert age to numeric\n",
    "# Gender \n",
    "df['SEX'] = pd.to_numeric(df['SEX'], errors='coerce')\n",
    "    # convert sex to numeric \n",
    "df['Male'] = df['SEX'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being male\n",
    "\n",
    "#Martial Status\n",
    "    # 1-Married\n",
    "    # 2-Divorced\n",
    "    # 3-Separated\n",
    "    # 4-Widowed\n",
    "    # 5-Never married\n",
    "df['MAR'] = pd.to_numeric(df['MAR'], errors='coerce')   \n",
    "    # convert marital status to numeric \n",
    "df['MARRIED'] = df['MAR'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being married and 0 being not married\n",
    "\n",
    "#Continental Origin, In the hopes of making the data more manageable, I will only group people by continent of origin not country. \n",
    "df['MIGSP'] = pd.to_numeric(df['MIGSP'], errors='coerce')\n",
    "    # convert continental origin to numeric \n",
    "df['EURO'] = df['MIGSP'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being European and 0 being non-European\n",
    "df['AFRICA'] = df['MIGSP'].map(lambda x: 1 if x == 2 else 0)\n",
    "    # changes it into a binary, 1 being African and 0 being non-African\n",
    "df['NORTH'] = df['MIGSP'].map(lambda x: 1 if x == 3 else 0)\n",
    "    # changes it into a binary, 1 being North American and 0 being non-North American\n",
    "df['South'] = df['MIGSP'].map(lambda x: 1 if x == 4 else 0)\n",
    "    # changes it into a binary, 1 being South/Central American and 0 being non-South American\n",
    "df['ASIA'] = df['MIGSP'].map(lambda x: 1 if x == 5 else 0)\n",
    "    # changes it into a binary, 1 being Asian and 0 being non-Asian\n",
    "df['OCEANIA'] = df['MIGSP'].map(lambda x: 1 if x == 6 else 0)\n",
    "    # changes it into a binary, 1 being Oceanian and 0 being non-Oceanian\n",
    "\n",
    "#Hispanic Origin\n",
    "df['HISP'] = pd.to_numeric(df['HISP'], errors='coerce')\n",
    "df['HISPANIC'] = df['HISP'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being Hispanic and 0 being non-Hispanic\n",
    "\n",
    "#Race\n",
    "df['RACWHT'] = pd.to_numeric(df['RACWHT'], errors='coerce')\n",
    "df['RACBLK'] = pd.to_numeric(df['RACBLK'], errors='coerce')\n",
    "df['WHITE'] = df['RACWHT'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being White and 0 being non-White\n",
    "df['BLACK'] = df['RACBLK'].map(lambda x: 1 if x == 1 else 0)\n",
    "    # changes it into a binary, 1 being Black and 0 being non-Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           LOG_WAGE        ENGLISH           NOHS             HS  \\\n",
      "count  3.578170e+05  357817.000000  357817.000000  357817.000000   \n",
      "mean           -inf       0.772414       0.233974       0.209562   \n",
      "std             NaN       0.419274       0.423357       0.406997   \n",
      "min            -inf       0.000000       0.000000       0.000000   \n",
      "25%             NaN       1.000000       0.000000       0.000000   \n",
      "50%    9.680344e+00       1.000000       0.000000       0.000000   \n",
      "75%    1.075790e+01       1.000000       0.000000       0.000000   \n",
      "max    1.348283e+01       1.000000       1.000000       1.000000   \n",
      "\n",
      "                COLL           BACH           POST           AGEP  \\\n",
      "count  357817.000000  357817.000000  357817.000000  357817.000000   \n",
      "mean        0.206368       0.194267       0.155828      49.904761   \n",
      "std         0.404698       0.395636       0.362693      17.098871   \n",
      "min         0.000000       0.000000       0.000000      18.000000   \n",
      "25%         0.000000       0.000000       0.000000      37.000000   \n",
      "50%         0.000000       0.000000       0.000000      49.000000   \n",
      "75%         0.000000       0.000000       0.000000      62.000000   \n",
      "max         1.000000       1.000000       1.000000      96.000000   \n",
      "\n",
      "                Male        MARRIED           EURO         AFRICA     NORTH  \\\n",
      "count  357817.000000  357817.000000  357817.000000  357817.000000  357817.0   \n",
      "mean        0.469740       0.639282       0.000486       0.000159       0.0   \n",
      "std         0.499084       0.480209       0.022046       0.012620       0.0   \n",
      "min         0.000000       0.000000       0.000000       0.000000       0.0   \n",
      "25%         0.000000       0.000000       0.000000       0.000000       0.0   \n",
      "50%         0.000000       1.000000       0.000000       0.000000       0.0   \n",
      "75%         1.000000       1.000000       0.000000       0.000000       0.0   \n",
      "max         1.000000       1.000000       1.000000       1.000000       0.0   \n",
      "\n",
      "               South           ASIA        OCEANIA       HISPANIC  \\\n",
      "count  357817.000000  357817.000000  357817.000000  357817.000000   \n",
      "mean        0.002448       0.000271       0.023685       0.612207   \n",
      "std         0.049419       0.016463       0.152067       0.487248   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       1.000000   \n",
      "75%         0.000000       0.000000       0.000000       1.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "               WHITE          BLACK  \n",
      "count  357817.000000  357817.000000  \n",
      "mean        0.478242       0.082198  \n",
      "std         0.499527       0.274667  \n",
      "min         0.000000       0.000000  \n",
      "25%         0.000000       0.000000  \n",
      "50%         0.000000       0.000000  \n",
      "75%         1.000000       0.000000  \n",
      "max         1.000000       1.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "c:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\numpy\\lib\\function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    }
   ],
   "source": [
    "#Summary \n",
    "df.dropna(inplace=True) # drop missing values in data set\n",
    "selected_columns = ['LOG_WAGE', 'ENGLISH', 'NOHS', 'HS', 'COLL', 'BACH', 'POST', 'AGEP', 'Male', 'MARRIED', 'EURO', 'AFRICA', 'NORTH', 'South', 'ASIA', 'OCEANIA', 'HISPANIC', 'WHITE', 'BLACK']\n",
    "summary = df[selected_columns].describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RACBLK      0\n",
      "RACAIAN     0\n",
      "RACWHT      0\n",
      "MAR         0\n",
      "SEX         0\n",
      "ENG         0\n",
      "HISP        0\n",
      "SCHL        0\n",
      "MIGSP       0\n",
      "YOEP        0\n",
      "AGEP        0\n",
      "WAGP        0\n",
      "NATIVITY    0\n",
      "LOG_WAGE    0\n",
      "ENGLISH     0\n",
      "NOHS        0\n",
      "HS          0\n",
      "COLL        0\n",
      "BACH        0\n",
      "POST        0\n",
      "Male        0\n",
      "MARRIED     0\n",
      "EURO        0\n",
      "AFRICA      0\n",
      "NORTH       0\n",
      "South       0\n",
      "ASIA        0\n",
      "OCEANIA     0\n",
      "HISPANIC    0\n",
      "WHITE       0\n",
      "BLACK       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isinf' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check for NaNs and Infs\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())  \u001b[38;5;66;03m# Count NaNs in each column\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum())  \u001b[38;5;66;03m# Count Infs in each column\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\pandas\\core\\generic.py:2168\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2164\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   2165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_ufunc__\u001b[39m(\n\u001b[0;32m   2166\u001b[0m     \u001b[38;5;28mself\u001b[39m, ufunc: np\u001b[38;5;241m.\u001b[39mufunc, method: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m   2167\u001b[0m ):\n\u001b[1;32m-> 2168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marraylike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\pandas\\core\\arraylike.py:407\u001b[0m, in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__call__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# for np.<ufunc>(..) calls\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# kwargs cannot necessarily be handled block-by-block, so only\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# take this path if there are no kwargs\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[1;32m--> 407\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# otherwise specific ufunc methods (eg np.<ufunc>.accumulate(..))\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m# Those can have an axis keyword and thus can't be called block-by-block\u001b[39;00m\n\u001b[0;32m    411\u001b[0m     result \u001b[38;5;241m=\u001b[39m default_array_ufunc(inputs[\u001b[38;5;241m0\u001b[39m], ufunc, method, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:362\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m obj[b\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mindexer]\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[1;32m--> 362\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    364\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isinf' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "# Check for NaNs and Infs\n",
    "print(df.isnull().sum())  # Count NaNs in each column\n",
    "print(np.isinf(df).sum())  # Count Infs in each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaNs\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Impute NaNs with a specific value\n",
    "#df.fillna(value, inplace=True)\n",
    "\n",
    "# Replace Infs with a specific value\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with Infs\n",
    "df = df[~df.isin([np.inf, -np.inf]).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.359015\n",
      "         Iterations 7\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m Predictor_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOG_WAGE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOHS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOLL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBACH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGEP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMARRIED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEURO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFRICA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNORTH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSouth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASIA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOCEANIA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHISPANIC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWHITE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBLACK\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m probit_model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mProbit(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mENGLISH\u001b[39m\u001b[38;5;124m'\u001b[39m], df[Predictor_columns]) \n\u001b[1;32m----> 4\u001b[0m probit_result \u001b[38;5;241m=\u001b[39m \u001b[43mprobit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# fit probit model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2911\u001b[0m, in \u001b[0;36mProbit.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   2908\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(DiscreteModel\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[0;32m   2909\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m,\n\u001b[0;32m   2910\u001b[0m         full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2911\u001b[0m     bnryfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2912\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2913\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2914\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2915\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2916\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2917\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2918\u001b[0m     discretefit \u001b[38;5;241m=\u001b[39m ProbitResults(\u001b[38;5;28mself\u001b[39m, bnryfit)\n\u001b[0;32m   2919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[1;32mc:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:243\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "File \u001b[1;32mc:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\statsmodels\\base\\model.py:582\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m cov_params_func(\u001b[38;5;28mself\u001b[39m, xopt, retvals)\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m full_output:\n\u001b[1;32m--> 582\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mretvals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHessian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hessian:\n\u001b[0;32m    584\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhessian(xopt)\n",
      "File \u001b[1;32mc:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\numpy\\linalg\\linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\Exq4880\\Python\\HSDATA\\DATA\\Lib\\site-packages\\numpy\\linalg\\linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "#regression model\n",
    "Predictor_columns = ['LOG_WAGE', 'NOHS', 'HS', 'COLL', 'BACH', 'POST', 'AGEP', 'Male', 'MARRIED', 'EURO', 'AFRICA', 'NORTH', 'South', 'ASIA', 'OCEANIA', 'HISPANIC', 'WHITE', 'BLACK']\n",
    "probit_model = sm.Probit(df['ENGLISH'], df[Predictor_columns]) \n",
    "probit_result = probit_model.fit() # fit probit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education Attainment\n",
    "# 01-15 -Did not complete high school. \n",
    "# 16-High school graduate - regular high school diploma; \n",
    "# 17-High school graduate - GED or alternative credential\n",
    "# 18-19-Some college, no degree, \n",
    "# 20-Associate's degree; \n",
    "# 21-Bachelor's degree; \n",
    "# 22-24-Post graduate degree;\n",
    "# High School & GED\n",
    "Eng$HS<- ifelse(Eng$SCHL ==\"16\"|Eng$SCHL==\"17\", 1,0)\n",
    "# Some College & Associate \n",
    "Eng$SC<- ifelse(Eng$SCHL ==\"18\"| Eng$SCHL == \"19\" | Eng$SCHL == \"20\", 1,0)\n",
    "# Bachelor's Degree \n",
    "Eng$BACH <- ifelse(Eng$SCHL ==\"21\",1,0)\n",
    "# Post undergraduate \n",
    "Eng$GRAD <- ifelse(Eng$SCHL == \"22\" | Eng$SCHL == \"23\" | Eng$SCHL == \"24\", 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Initialize Ridge regression model with regularization parameter alpha\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "\n",
    "# Fit Ridge regression model\n",
    "ridge_model.fit(X_train, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DATA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
